# -*- coding: utf-8 -*-
"""Furkan_Dogan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XD6PflZeeB-F1GJhgH9Qc1pEMzB_HT8u
"""

#Gerekli paketler yüklendi.
!pip install opencv-python
!pip install matplotlib-venn
!apt-get -qq install -y libfluidsynth1
!pip install -U scikit-learn
!pip install scikit-learn

#Google drive erişim sağladık.
from google.colab import drive
drive.mount('/content/drive')

#"warning" olarak adlandırılan uyarı mesajlarını önlemek için kullanılır.
import warnings
warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

import numpy as np # Sayısal işlemlerde kullanılan kütüphane.
import pandas as pd # Veri anlama ve veri işlemede kullanılan kütüphane.
import matplotlib.pyplot as plt # Grafikler oluşturmak için kullanılan kütüphane.
from matplotlib import style # Grafiklerin stilini değiştirmeye yarayan kütüphane.
import seaborn as sns # Matplotlib kütüphanesine ek özellikler ekleyerek daha güzel görüntülenebilen grafikler oluşturmaya yardımcı olan kütüphane.
import missingno as msno #  Veri kümesinde eksik verileri bulmaya yardımcı olan kütüphane.

#Grafiklerin görünümünü ayarlamak için kullanılır. 
#%matplotlib inline  
style.use('fivethirtyeight')
sns.set(style='whitegrid',color_codes=True)

#Farklı sınıflandırma modellerini içeren sklearn kütüphanesinden modelleri içeren kısım.
from sklearn.linear_model import LogisticRegression# Logistic Regression sınıfını içe aktar.
from sklearn.svm import LinearSVC# Linear Support Vector Classification sınıfını içe aktar.
from sklearn.svm import SVC# Support Vector Classification sınıfını içe aktar.
from sklearn.neighbors import KNeighborsClassifier# K-Nearest Neighbors Classification sınıfını içe aktar.
from sklearn.ensemble import RandomForestClassifier# Random Forest Classification sınıfını içe aktar.
from sklearn.tree import DecisionTreeClassifier# Decision Tree Classification sınıfını içe aktar.
from sklearn.ensemble import GradientBoostingClassifier# Gradient Boosting Classification sınıfını içe aktar.
from sklearn import datasets# Veri kümelerini içe aktar.
from sklearn.naive_bayes import GaussianNB# Gaussian Naive Bayes sınıfını içe aktar.

# Fonksiyonu, verilerin eğitim ve test veri kümelerine bölünmesine yardımcı olur.
from sklearn.model_selection import train_test_split 
# Fonksiyonu, verilerin katlama yöntemi ile bölünmesine yardımcı olur.
from sklearn.model_selection import KFold 
# Gibi fonksiyonlar, modelin performansını ölçmek için kullanılır.
from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score,classification_report 
# Veri kümesinde en iyi parametreleri bulmak için hiperparametre ayarlamaları yapar.
from sklearn.model_selection import GridSearchCV

from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder,OneHotEncoder # Verileri ölçeklendirme ve sınıf etiketlerini dönüştürme sınıflarını içe aktar.
train=pd.read_csv("/content/drive/My Drive/voice.csv") # voice.csv dosyasından veri oku.
df=train.copy() # Veri kümesinin bir kopyasını oluştur.

df.isnull().any() # Eksik veri olup olmadığını kontrol et.
msno.matrix(df) # Eksik verileri gösteren görsel oluştur.

train.head().style.background_gradient(cmap='coolwarm') # Veri kümesinin ilk beş satırını göster ve değerleri renklerle belirt.

# Korelasyon ısı haritasını oluştur.
plt.figure(figsize=(15, 8)) 
mask = np.triu(np.ones_like(train.corr(), dtype=bool))
sns.heatmap(train.corr(), mask = mask, annot=True, cmap='Dark2');

# Nitelikler arasındaki korelasyonu ve sınıf değişkenine göre dağılımı gösteren çoklu görsel oluştur.
sns.pairplot(train , hue = 'label',palette='Dark2',corner=True )

#Sınıf ve örnek sayısı.
#df.shape

# Veri kümesinde bir niteliğin çıkış noktalarını gösteren kutu grafiği ve dağılımını gösteren histogram oluştur.
def calc_limits(feature):
    # Niteliğin yüzde 25 ve yüzde 75'leri kullanılarak IQR hesapla.
    q1,q3=df[feature].quantile([0.25,0.75])
    iqr=q3-q1
    # Çıkış noktalarının sınırlarını hesapla.
    rang=1.5*iqr
    return(q1-rang,q3+rang)
    
def plot(feature):
    # İki adet eksen oluştur.
    fig,axes=plt.subplots(1,2)
    # Kutu grafiği oluştur.
    sns.boxplot(data=df,x=feature,ax=axes[0])
    # Histogram oluştur.
    sns.distplot(a=df[feature],ax=axes[1],color='#ff4125')
    # Görsel boyutunu ayarla.
    fig.set_size_inches(15,5)
    lower,upper = calc_limits(feature) # Çıkış noktalarının sınırlarını hesapla.
    l=[df[feature] for i in df[feature] if i>lower and i<upper] # Çıkış noktaları haricinde kalan veri noktalarını say.
    print("Number of data points remaining if outliers removed : ",len(l)) # Ekrana veri kümesinde bu niteliğin çıkış noktaları haricinde kalan veri noktalarının sayısını yazdır.


plot('meanfreq') #Niteliğinin çıkış noktalarını gösteren bir kutu grafiği ve bu niteliğin dağılımını gösteren bir histogram oluştur.

sns.histplot(train['median'],kde=True,color='purple',bins=30) # "median" niteliğinin dağılımını gösteren histogram oluştur

plot('sd') # "sd" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('median') # "median" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('Q25') # "Q25" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('IQR') # "IQR" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('skew') # "skew" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('kurt') # "kurt" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('sfm') # "sfm" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

plot('meanfun') # "meanfun" niteliğinin çıkış noktalarını gösteren kutu grafik ve dağılımını gösteren histogram oluştur.

# "label" niteliğini ikili değerlere çevir.
temp = []
# Döngü, veri kümesinde "label" niteliğinin her bir değerini dolaş.

for i in df.label:
    # Eğer "label" niteliği "male" değeri içeriyorsa,
    if i == 'male':
        # temp listesine 1 değerini ekle
        temp.append(1)
    # Diğer tüm değerler için  ,  
    else:
        # temp listesine 0 değerini ekle.
        temp.append(0)
# "label" niteliğini ikili değerler olarak güncelle   .     
df['label'] = temp
# Veri kümesinin nitelikleri arasındaki korelasyonu gösteren ısı haritası oluştur.
# Korelasyon matrisini oluştur.
cor_mat= df[:].corr()
# Korlasyon matrisine ait maskenin oluştur.
mask = np.array(cor_mat)
# Maskedeki alt triyagonal elemanların değiştir.
mask[np.tril_indices_from(mask)] = False
# İşlem sonucunun gösterileceği figure nesnesinin oluştur.
fig=plt.gcf()
# Figure nesnesinin boyutunun ayarla.
fig.set_size_inches(30,12)
# İşlem sonucunun göster.
sns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)

df.drop('centroid',axis=1,inplace=True) # Veri kümesinden "centroid" niteliğini kaldır.

# Tüm sütunlar üzerinde döngü oluştur.
for col in df.columns:
    # Her bir sütun için alt ve üst sınırları hesapla.
    lower,upper=calc_limits(col)
    # Veri kümesinden, sütunların değerleri sınırların dışına çıkan satırları kaldır.
    df = df[(df[col] >lower) & (df[col]<upper)]
# İşlem sonucu oluşan veri kümesinin boyutunu yazdır.
df.shape

temp_df=df.copy() # Veri kümesinin bir kopyasını oluştur
temp_df.drop(['skew','kurt','mindom','maxdom'],axis=1,inplace=True) # "skew", "kurt", "mindom", "maxdom" niteliklerini kaldır
temp_df.head(10 )# İşlem sonucu oluşan veri kümesinin ilk 10 satırını yazdır

#Bu işlemlerin amacı, veri kümesindeki değişkenler arasındaki dağılımları görselleştirmektir.
temp_df['meanfreq']=temp_df['meanfreq'].apply(lambda x:x*2) # "meanfreq" sütununun tüm değerlerini ikiyle çarp.
temp_df['median']=temp_df['meanfreq']+temp_df['mode'] # "median" sütununun değerlerini "meanfreq" ve "mode" sütunlarının değerlerinin toplamı olarak ata.
temp_df['median']=temp_df['median'].apply(lambda x:x/3) # "median" sütununun değerlerini üçe böl.
sns.boxplot(data=temp_df,y='median',x='label')# "median" sütununun "label" sütununa göre boxplot'ı oluştur.

from sklearn import tree
 

# Veri çerçevesinden etiket değişkenini düşürün ve değişkenleri standartlaştır.
scaler=StandardScaler()
scaled_df=scaler.fit_transform(temp_df.drop('label',axis=1))
X=scaled_df
Y=df['label']

# Eğitim ve test verilerini ayırın
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)

#Bu kod parçacığında, veri kümesinden bir karar ağacı ve rastgele ormanı kullanarak sınıflandırma modelleri eğitilmektedir.
# Karar ağacı modelini oluşturun ve eğit.
clf_dt=DecisionTreeClassifier()
clf_dt.fit(x_train,y_train)

# Karar ağacı modelini görsel olarak çizdir.
plt.figure(figsize=(30,18))
tree.plot_tree(clf,filled=True)
plt.show()

# Karar ağacı modelinin test verisi üzerinden tahminler yapın ve doğruluk skoru hesapla.
pred=clf_dt.predict(x_test)
print("Karar ağacı modeli doğruluk oranı: ",accuracy_score(pred,y_test))

# Rastgele orman modelini oluşturun ve eğit.
clf_rf=RandomForestClassifier()
clf_rf.fit(x_train,y_train)

# Rastgele orman modelinin test verisi üzerinden tahminler yapın ve doğruluk skoru hesapla.
pred=clf_rf.predict(x_test)
print("Rastgele orman modeli doğruluk oranı: ", accuracy_score(pred,y_test))

import matplotlib.pyplot as plt
import seaborn as sns

pred = clf_rf.predict(x_test) # modelden tahminler yap.
conf_matrix = confusion_matrix(y_test, pred) # confusion matrix oluştur.

#RandomForestClassifier confusion matrix'i grafik şeklinde gösterin
ax= plt.subplot()
 # confusion matrix'i "Greens" renk paletiyle göster.
sns.heatmap(conf_matrix, annot=True, ax = ax, cmap='Greens', fmt='g')

# Eksen etiketlerini ayarla.
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix') 
ax.xaxis.set_ticklabels(['0', '1'])
ax.yaxis.set_ticklabels(['0', '1'])

import matplotlib.pyplot as plt
import seaborn as sns

pred = clf_dt.predict(x_test) # modelinizden tahminler yap.
conf_matrix = confusion_matrix(y_test, pred) # confusion matrix oluştur.

#DecisionTreeClassifier confusion matrix'i grafik şeklinde göster.
ax= plt.subplot()
# confusion matrix'i "Greens" renk paletiyle göster.
sns.heatmap(conf_matrix, annot=True, ax = ax, cmap='Greens', fmt='g') 

# Eksen etiketlerini ayarla.
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix') 
ax.xaxis.set_ticklabels(['0', '1'])
ax.yaxis.set_ticklabels(['0', '1'])

#DecisionTree Sınıflandırmasına ait Cross Valudation kısmı.
# Karar ağacı sınıflandırma modeline ait k-katlı çapraz doğrulama (k-fold cross validation) işlemini gerçekleştir.
from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator=clf, X=x_train, y=y_train, cv=10)
# Elde edilen doğruluk skorlarını yazdır.
accuracies

#Cross Valudation değerinin ortalaması.
accuracies.mean()

#Cross Valudation değerinin standart sapması.
accuracies.std()

#Ensemble Sınıflandırmasına ait olan K-Komşu Sınıflandırmasını kullandığım kısım.
# K-en yakın komşu (K-NN) sınıflandırma algoritmasını import et
from sklearn.neighbors import KNeighborsClassifier


# Eğitim ve test doğruluk skorlarını tutacak boş listeler oluştur.
trainAccuracy=[]
testAccuracy=[]

# Komşu sayısını 1 ile 40 arasında döndür.
for k in range(1,40):
    # K-NN modelini oluşturun ve eğit. 
    model=KNeighborsClassifier(n_neighbors=k)
    model.fit(x_train, y_train)
    # Eğitim ve test verileri üzerinden doğruluk skorlarını hesaplayın ve listelere ekle.
    trainAccuracy.append(model.score(x_train, y_train))
    testAccuracy.append(model.score(x_test, y_test))

#Tablolarda ki görsellik için gereken matplotlib kütüphanesini import edip stilini seçtiğim kısım.
# Matplotlib kütüphanesini import edin ve stilini ayarla.
from matplotlib import pyplot as plt,style
style.use('ggplot')

#Bu aşamada eğitim ve test skorlarının K-Komşu sayılarına göre olan değişimi gözlenmektedir.
#Komşu sayısı arttıkça hem eğitim hemde test skoru azalmaktadır. (Özellikle eğitim skoru)
plt.figure(figsize=(14,7))
plt.plot(range(1,40),trainAccuracy,label="Eğitim Skoru",marker="o",markerfacecolor="teal",color="blue",linestyle="dashed")
plt.plot(range(1,40),testAccuracy,label="Test Skoru",marker="o",markerfacecolor="red",color="black",linestyle="dashed")
plt.legend()
plt.xlabel("Komşu Sayısı")
plt.ylabel("Skor")
plt.title("NBD vs SKOR")
plt.show()

# Rastgele orman ve karar ağacı sınıflandırma modellerini tutan liste oluştur.
models=[RandomForestClassifier(), DecisionTreeClassifier()]

# Model isimlerini tutan liste oluştur.
model_names=['RandomForestClassifier','DecisionTree']

# Doğruluk skorlarını tutacak boş liste oluştur.
acc=[]

# Boş bir sözlük oluştur.
d={}

# Model listesi boyunca döngü oluştur.
for model in range(len(models)):
    # Modeli oluşturun ve eğit.
    clf=models[model]
    clf.fit(x_train,y_train)
    # Test verisi üzerinden tahminler yap.
    pred=clf.predict(x_test)
    # Tahminlerin doğruluk skorunu hesaplayın ve listeye ekle.
    acc.append(accuracy_score(pred,y_test))

# Doğruluk skorlarını sözlükte sakla.  
d={'Modelling Algo':model_names,'Accuracy':acc}

# Sözlükten veri frame'i oluştur.
acc_frame=pd.DataFrame(d)

# Bar plot çizdir.
sns.barplot(y='Modelling Algo',x='Accuracy',data=acc_frame)

# Rastgele orman sınıflandırma modeli için parametrelerin belirlendiği grid oluştur.
#Bu kod bloğu, "RandomForestClassifier()" sınıfının bir nesnesini oluşturur ve bu nesnenin parametrelerini "GridSearchCV()" fonksiyonu ile arama işlemi yapar.
# "GridSearchCV()" fonksiyonu, modelimizin performansını optimize etmek için verilen parametrelerin değerlerini değiştirerek modeli eğitir ve test eder.
#Bu kod bloğunda, "cv" parametresi ile belirtilen 5'e göre k-fold cross-validation uygulanır. Bu, veri kümenizi 5'e bölerek, her bir bölümden birini test verisi olarak kullanarak toplam 5 defa modeli eğitir ve test eder.
param_grid = { 
    'n_estimators': [200, 500],# Ağaç sayısı
    'max_features': ['auto', 'sqrt', 'log2'], # Özelliklerin seçimi için kullanılacak yöntem
    'max_depth' : [4,5,6,7,8],# Ağaç derinliği
    'criterion' :['gini', 'entropy']# Kriter fonksiyonu
}
# GridSearchCV ile model oluşturun ve eğit.
CV_rfc = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, scoring='accuracy', cv= 5)
CV_rfc.fit(x_train, y_train)

# En iyi skor ve parametreleri yazdır.
print("Best score : ",CV_rfc.best_score_)
print("Best Parameters : ",CV_rfc.best_params_)
# Test verisindeki tahminlerin doğruluk skorunu yazdır.
print("Precision Score : ", precision_score(CV_rfc.predict(x_test),y_test))

# Özelliklerin önem sıralamasını oluşturun ve görselleştir.
df1 = pd.DataFrame.from_records(x_train)     
# Özelliklerin önemini tutan bir sütun oluştur.
tmp = pd.DataFrame({'Feature': df1.columns, 'Feature importance': clf_rf.feature_importances_})
# Önem sırasına göre sırala.
tmp = tmp.sort_values(by='Feature importance',ascending=False)
# Özelliklerin önemini görselleştir.
plt.figure(figsize = (7,4))
plt.title('Features importance',fontsize=14)
s = sns.barplot(x='Feature',y='Feature importance',data=tmp)
s.set_xticklabels(s.get_xticklabels(),rotation=90)
plt.show()